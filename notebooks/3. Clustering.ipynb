{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import h5py\n",
    "from io import StringIO\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "import itertools\n",
    "import xlsxwriter as Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/raw\"\n",
    "#converts to df to binary dataframe, 0 representing that the previous value was 0, and 1 indicating a nonzero value\n",
    "def df_to_binary(df_expression):    \n",
    "    temp = df_expression.copy()\n",
    "    num_rows = len(temp)\n",
    "    for c in range(len(df_expression.columns)):\n",
    "        nonzero_inds = df_expression.iloc[:,c].to_numpy().nonzero()[0]\n",
    "        temp_col = np.zeros(num_rows)\n",
    "        temp_col[nonzero_inds] = 1\n",
    "        temp.iloc[:,c] = temp_col\n",
    "    return(temp)\n",
    "\n",
    "\n",
    "\n",
    "def normalize(X):\n",
    "    return (X - np.mean(X,axis=1).reshape(X.shape[0],1))/np.linalg.norm((X - np.mean(X,axis=1).reshape(X.shape[0],1)),ord=2,axis=1).reshape(X.shape[0],1)\n",
    "\n",
    "\n",
    "#INPUTS:\n",
    "#  file_list: list of csv filenames containing expression data. Will concatenate these matrices together and compute distances\n",
    "def preprocess_samples(file_list):\n",
    "    sample_source = []\n",
    "    # Merge all of the files into one dataframe\n",
    "    df_expression = pd.read_csv(os.path.join(data_path,file_list[0]),index_col = 0,sep=\"\\t\")\n",
    "    sample_source.extend(np.repeat(file_list[0],len(df_expression.columns)))\n",
    "    for filename in file_list[1:]:\n",
    "        temp = pd.read_csv(os.path.join(data_path,filename),index_col = 0, sep = \"\\t\")\n",
    "        sample_source.extend(np.repeat(filename,len(temp.columns)))\n",
    "        df_expression = df_expression.merge(temp,right_index=True,left_index=True)\n",
    "    \n",
    "    df_expression.columns = pd.Series(df_expression.columns)\n",
    "    df_expression.index = pd.Series(df_expression.index)\n",
    "    \n",
    "    return(df_expression,sample_source)    \n",
    "\n",
    "def hierarchical_clustering(df,title,method=\"average\",metric=\"euclidean\"):\n",
    "    clustering = shc.linkage(df, method=method, metric=metric)\n",
    "    plt.figure(figsize=(25, 20))  \n",
    "    plt.title(title)  \n",
    "\n",
    "    dend = shc.dendrogram(clustering) \n",
    "    print(\"Cophenet = \" + str(cophenet(clustering, pdist(df))[0]))\n",
    "    return(clustering)\n",
    "\n",
    "#INPUTS: \n",
    "#  h5filepath: path where the full matrix is stored with meta and expression data\n",
    "#  subsamples: a pandas DataFrame that must contain a column (foreign key) called SampleGeoAccession\n",
    "#OUTPUT\n",
    "#  merged dataframe of length(subsamples) merged with relevant meta/Sample values for cluster analysis\n",
    "def h5_sample_meta_lookup(h5filepath,subsamples):\n",
    "    f = h5py.File(h5filepath, 'r')\n",
    "    full_data = pd.DataFrame({\"Description\":f[(\"meta/Sample_description\")], \n",
    "                          \"Characteristics\":f[(\"meta/Sample_characteristics_ch1\")],\n",
    "                          \"SampleGeoAccession\":f[(\"meta/Sample_geo_accession\")],\n",
    "                          \"Series ID\":f[(\"meta/Sample_series_id\")],\n",
    "                          \"Molecule\":f[\"meta/Sample_molecule_ch1\"],\n",
    "                          \"Source Name\":f[\"meta/Sample_title\"]})\n",
    "    f.close()\n",
    "    full_data[\"SampleGeoAccession\"] = full_data[\"SampleGeoAccession\"].apply(lambda x : x.decode(\"utf-8\"))\n",
    "    cluster_meta = subsamples.merge(full_data,on=\"SampleGeoAccession\",how=\"left\")\n",
    "    cluster_meta[\"Sample_Label\"] = pd.Series(sample_source).str.replace(\".csv\",\"\").str.replace(\"_expression\",\" \")\n",
    "    cluster_meta[\"Series ID\"] = cluster_meta[\"Series ID\"].str.decode(\"utf-8\").str.replace(\"Xx\",\"\").str.replace(\"xX\",\"\")\n",
    "    cluster_meta[\"Molecule\"] = cluster_meta[\"Molecule\"].str.decode(\"utf-8\")\n",
    "    cluster_meta[\"Source Name\"] = cluster_meta[\"Source Name\"].str.decode(\"utf-8\")\n",
    "    cluster_meta[\"Description\"] = cluster_meta[\"Description\"].str.decode(\"utf-8\").str.replace(\"Xx\",\"\").str.replace(\"xX\",\"\")\n",
    "    cluster_meta[\"Characteristics\"] = cluster_meta[\"Characteristics\"].str.decode(\"utf-8\").str.replace(\"Xx\",\"\").str.replace(\"xX\",\"\")\n",
    "    return(cluster_meta)\n",
    "\n",
    "def purity_to_excel(cluster_metadata_metrics, H0, outfile):\n",
    "    workbook = Excel.Workbook(\"tables/\" +outfile +\".xlsx\")\n",
    "    worksheet = workbook.add_worksheet()\n",
    "    cluster_format = workbook.add_format({'bold': True, 'align':'center'})\n",
    "    center = workbook.add_format({'align': 'center'})\n",
    "\n",
    "    # Add a format. Light red fill with dark red text.\n",
    "    format1 = workbook.add_format({'bg_color': '#FFC7CE',\n",
    "                                   'font_color': '#9C0006'})\n",
    "\n",
    "    # Add a format. Green fill with dark green text.\n",
    "    format2 = workbook.add_format({'bg_color': '#C6EFCE',\n",
    "                                   'font_color': '#006100'})\n",
    "\n",
    "    worksheet.write('A1', \"Cluster ID\",cluster_format)\n",
    "    worksheet.write('B1', \"Cluster Size\",center)\n",
    "    worksheet.write('C1', \"Dominant Molecule\",center)\n",
    "    worksheet.write('D1', \"Molecule Purity\",center)\n",
    "    worksheet.write('E1', \"Dominant Series\",center)\n",
    "    worksheet.write('F1', \"Series Purity\",center)\n",
    "    worksheet.write('G1', \"Dominant Label\",center)\n",
    "    worksheet.write('H1', \"Label Purity\",center)\n",
    "    worksheet.write('I1', \"Null Hypothesis Value\",center)\n",
    "\n",
    "    worksheet.set_column(1, 7, 15)\n",
    "\n",
    "    num_keys = len(list(cluster_metadata_metrics.keys()))\n",
    "\n",
    "    j = 1\n",
    "    for i in np.sort(list(cluster_metadata_metrics.keys())):\n",
    "        worksheet.write(j,0,i,center)\n",
    "        worksheet.write(j,1,cluster_metadata_metrics[i][\"Size\"],center)\n",
    "        worksheet.write(j,2,list(cluster_metadata_metrics[i][\"Molecule Purity\"].keys())[0],center)\n",
    "        worksheet.write(j,3,list(cluster_metadata_metrics[i][\"Molecule Purity\"].values())[0],center)\n",
    "        worksheet.write(j,4,list(cluster_metadata_metrics[i][\"Series Purity\"].keys())[0],center)\n",
    "        worksheet.write(j,5,list(cluster_metadata_metrics[i][\"Series Purity\"].values())[0],center)\n",
    "        worksheet.write(j,6,list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0],center)\n",
    "        worksheet.write(j,7,list(cluster_metadata_metrics[i][\"Label Purity\"].values())[0],center)\n",
    "        worksheet.write(j,8,H0[list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0]],center)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Write a conditional format over a range.\n",
    "        worksheet.conditional_format('H'+str(j+1), {'type': 'cell',\n",
    "                                             'criteria': '>=',\n",
    "                                             'value': H0[list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0]],\n",
    "                                             'format': format2})\n",
    "\n",
    "        # Write another conditional format over the same range.\n",
    "        worksheet.conditional_format('H'+str(j+1), {'type': 'cell',\n",
    "                                             'criteria': '<',\n",
    "                                             'value': H0[list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0]],\n",
    "                                             'format': format1})\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    workbook.close()\n",
    "\n",
    "\n",
    "def get_purity(cluster_assignments, df_expression_trans):\n",
    "    cluster_dict = {\"SampleGeoAccession\":[],\"ClusterAssignment\":[]}\n",
    "    cluster_dict[\"SampleGeoAccession\"] = df_expression_trans.index\n",
    "    cluster_dict[\"ClusterAssignment\"] = cluster_assignments\n",
    "    cluster_info = pd.DataFrame(cluster_dict)\n",
    "    cluster_metadata = h5_sample_meta_lookup(\"human_matrix.h5\",cluster_info).sort_values(\"ClusterAssignment\")\n",
    "    \n",
    "    #hypothesized values of expected sample frequencies assuming no separation (based on observed proportion of sample labels)\n",
    "    H0 = {}\n",
    "    for samp in cluster_metadata.Sample_Label:\n",
    "        H0[samp] = len(cluster_metadata[cluster_metadata.Sample_Label == samp])/len(cluster_metadata)\n",
    "    \n",
    "    cluster_metadata_metrics = {}\n",
    "    for c in range(1,k+1):\n",
    "        cluster_metadata_metrics[c] = {\"Size\":len(cluster_metadata.loc[cluster_metadata.ClusterAssignment == c]), \n",
    "                                       \"Molecule Purity\":{},\"Series Purity\":{},\"Label Purity\":{}}\n",
    "        series_counts = cluster_metadata.groupby('ClusterAssignment')[\"Series ID\"].value_counts()\n",
    "        molecule_counts = cluster_metadata.groupby('ClusterAssignment')[\"Molecule\"].value_counts()\n",
    "        label_counts = cluster_metadata.groupby('ClusterAssignment')[\"Sample_Label\"].value_counts()\n",
    "\n",
    "        series_purity_key = pd.Series(series_counts[c][series_counts[c] == series_counts[c].max()]).index[0]\n",
    "        series_purity_val = series_counts[c].max()/float(series_counts[c].sum())\n",
    "        cluster_metadata_metrics[c][\"Series Purity\"][series_purity_key] = round(series_purity_val,3)\n",
    "\n",
    "        molecule_purity_key = molecule_counts[c][molecule_counts[c] == molecule_counts[c].max()].index[0]\n",
    "        molecule_purity_val = molecule_counts[c].max()/float(molecule_counts[c].sum())\n",
    "        cluster_metadata_metrics[c][\"Molecule Purity\"][molecule_purity_key] = round(molecule_purity_val,3)\n",
    "\n",
    "        label_purity_key = label_counts[c][label_counts[c] == label_counts[c].max()].index[0]\n",
    "        label_purity_val = label_counts[c].max()/float(label_counts[c].sum())\n",
    "        cluster_metadata_metrics[c][\"Label Purity\"][label_purity_key] = round(label_purity_val,3)\n",
    "    purity_to_excel(cluster_metadata_metrics,H0,cluster_title+\" purity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"HT1080_expression.csv\", \"HCT116_expression.csv\",\"Colon_expression.csv\"]\n",
    "df_expression_raw,sample_source = preprocess_samples(file_list)\n",
    "\n",
    "gene_list = df_expression_raw.index\n",
    "sample_list  =df_expression_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_inds = list(np.random.choice(range(37,1572),200)) + list(range(37))\n",
    "df_expression_raw = df_expression_raw.iloc[random_inds,:]\n",
    "sample_source = np.array(sample_source)[random_inds]\n",
    "gene_list = df_expression_raw.index\n",
    "sample_list  =df_expression_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = ['AC004824.1', 'AC006427.2', 'AC010740.1', 'AC093084.1',\n",
    "       'AC130360.7', 'ADAM30', 'AF196972.4', 'AK9', 'AL355480.2', 'AP2M1',\n",
    "       'ARPC1A', 'ATG16L2', 'ATP5F1', 'BCL2L15', 'BCRP1', 'C12ORF66',\n",
    "       'CDR1', 'CEP128', 'CGA', 'CH17-13I23.3', 'CH507-236L23.4',\n",
    "       'CNN2P10', 'CTB-179I1.1', 'CTC-503J8.2', 'CTD-2014N11.1',\n",
    "       'CTD-2501O3.2', 'DIMT1', 'DLST', 'DMXL1', 'DNAJB1', 'EARS2',\n",
    "       'EIF4A1P9', 'FXYD1', 'GOLGA6L4', 'GPATCH8', 'GZMAP1', 'HEMK1',\n",
    "       'HMGB1P29', 'HS3ST6', 'IGHV2OR16-5', 'ITFG1', 'IYD', 'KDM4E',\n",
    "       'MCRS1', 'MT-CYB', 'NOL7', 'NUTF2P4', 'OR10A3', 'OR2L13',\n",
    "       'OR51A9P', 'OR9K2', 'PROSER2', 'PRSS53', 'REG4', 'RNPEP',\n",
    "       'RP1-20N2.7', 'RP11-404F10.6', 'RP11-411B10.4', 'RP11-548K12.6',\n",
    "       'RP11-989E6.13', 'RP3-509I19.1', 'RP3-511B24.5', 'RP4-593A12.1',\n",
    "       'RPL23AP48', 'RPL23AP54', 'RPL34P27', 'RPL36AL', 'SEC62', 'SETD9',\n",
    "       'SH3GL1P3', 'SLC10A6', 'SMC1B', 'STX7', 'SUGP1', 'TBX1', 'TGIF2',\n",
    "       'TPPP2', 'TUBB8P2', 'TUBBP10', 'USP17L28', 'VKORC1L1', 'WFDC6',\n",
    "       'WHRN', 'XCL2', 'ZC3H18', 'ZNF354C', 'ZNF449', 'ZNF705G']\n",
    "\n",
    "sample_list = df_expression_raw.columns\n",
    "\n",
    "df_expression_raw = df_expression_raw.loc[gene_list,sample_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = ['AC004824.1', 'AC006427.2', 'AC010740.1', 'AC093084.1',\n",
    "       'AC130360.7', 'ADAM30', 'AF196972.4', 'AK9', 'AL355480.2', 'AP2M1',\n",
    "       'ARPC1A', 'ATG16L2', 'ATP5F1', 'BCL2L15', 'BCRP1', 'C12ORF66',\n",
    "       'CDR1', 'CEP128', 'CGA', 'CH17-13I23.3', 'CH507-236L23.4',\n",
    "       'CNN2P10', 'CTB-179I1.1', 'CTC-503J8.2', 'CTD-2014N11.1',\n",
    "       'CTD-2501O3.2', 'DIMT1', 'DLST', 'DMXL1', 'DNAJB1', 'EARS2',\n",
    "       'EIF4A1P9', 'FXYD1', 'GOLGA6L4', 'GPATCH8', 'GZMAP1', 'HEMK1',\n",
    "       'HMGB1P29', 'HS3ST6', 'IGHV2OR16-5', 'ITFG1', 'IYD', 'KDM4E',\n",
    "       'MCRS1', 'MT-CYB', 'NOL7', 'NUTF2P4', 'OR10A3', 'OR2L13',\n",
    "       'OR51A9P', 'OR9K2', 'PROSER2', 'PRSS53', 'REG4', 'RNPEP',\n",
    "       'RP1-20N2.7', 'RP11-404F10.6', 'RP11-411B10.4', 'RP11-548K12.6',\n",
    "       'RP11-989E6.13', 'RP3-509I19.1', 'RP3-511B24.5', 'RP4-593A12.1',\n",
    "       'RPL23AP48', 'RPL23AP54', 'RPL34P27', 'RPL36AL', 'SEC62', 'SETD9',\n",
    "       'SH3GL1P3', 'SLC10A6', 'SMC1B', 'STX7', 'SUGP1', 'TBX1', 'TGIF2',\n",
    "       'TPPP2', 'TUBB8P2', 'TUBBP10', 'USP17L28', 'VKORC1L1', 'WFDC6',\n",
    "       'WHRN', 'XCL2', 'ZC3H18', 'ZNF354C', 'ZNF449', 'ZNF705G']\n",
    "sample_list = ['GSM1093236', 'GSM1649207', 'GSM1649201', 'GSM1649199',\n",
    "       'GSM1649206', 'GSM1649198', 'GSM1649205', 'GSM1649204',\n",
    "       'GSM1649208', 'GSM1649203', 'GSM1649197', 'GSM1649195',\n",
    "       'GSM1649191', 'GSM1649196', 'GSM1649212', 'GSM1980055',\n",
    "       'GSM1980058', 'GSM1980057', 'GSM1980056', 'GSM1649194',\n",
    "       'GSM3430684', 'GSM3430685', 'GSM2279678', 'GSM2279679',\n",
    "       'GSM2279680', 'GSM2279681', 'GSM2279682', 'GSM2279683',\n",
    "       'GSM2279684', 'GSM2279685']\n",
    "\n",
    "sample_source = [\"ALPHA\",\"ALPHA\",\"ALPHA\",\"ALPHA\",\"ALPHA\",\"ALPHA\",\"ALPHA\",\"ALPHA\",\"ALPHA\",\"ALPHA\",\"beta\",\n",
    "                \"beta\",\"beta\",\"beta\",\"beta\",\"beta\",\"beta\",\"beta\",\"beta\",\"beta\",\"PANC1\",\n",
    "                \"PANC1\",\"PANC1\",\"PANC1\",\"PANC1\",\"PANC1\",\"PANC1\",\"PANC1\",\"PANC1\",\"PANC1\",]\n",
    "df_expression_raw = df_expression_raw.loc[gene_list,sample_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_inds = (df_expression_raw.T != 0).any()\n",
    "df_nonzero = df_expression_raw[nonzero_inds]\n",
    "sample_source = np.array(sample_source)[nonzero_inds]\n",
    "gene_list = gene_list[nonzero_inds]\n",
    "df_expression_norm = pd.DataFrame(np.transpose(normalize(np.transpose(np.array(df_nonzero)))),columns=sample_list,index=gene_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method=\"average\"\n",
    "metric=\"euclidean\"\n",
    "#df_expression_trans = np.transpose(df_expression_norm)\n",
    "df_expression_trans = np.transpose(df_expression_raw)\n",
    "#df_expression_trans = np.transpose(df_to_binary(df_expression_trans))\n",
    "dataTitle=\"Normalized\"\n",
    "cluster_title = dataTitle +\" Data (Filtered) Ovary vs. SKOV3 cell \"+method+\"+\"+metric\n",
    "df_expression_trans = df_expression_norm\n",
    "genes = list(df_expression_trans.columns)\n",
    "samples = list(df_expression_trans.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = hierarchical_clustering(df_expression_trans, method=method, metric=metric, title = cluster_title + \" Dendrogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine k from above dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "cluster_assignments = fcluster(clustering, k, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_purity(cluster_assignments, df_expression_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The full pipeline in one function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gene filter is specified, do you wish to proceed to cluster on all 35238 genes?\n",
      "(99, 35238)\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Inputs\n",
    "\n",
    "h5_filepath = \"../data/raw/human_matrix.h5\"\n",
    "\n",
    "samples_filter_to = [\"GSM742947\",\"GSM979870\",\"GSM1196045\",\"GSM979869\",\"GSM1505605\",\"GSM1548004\",\"GSM1548001\",\"GSM1548003\",\"GSM1505580\",\"GSM1547996\",\"GSM1548002\",\"GSM1548000\",\"GSM1547998\",\"GSM1547997\",\"GSM1547999\",\"GSM2343138\",\"GSM1101662\",\"GSM2344226\",\"GSM1010948\",\"GSM2453417\",\"GSM2343109\",\"GSM3415785\",\"GSM3415786\",\"GSM3415852\",\"GSM3415878\",\"GSM3613418\",\"GSM3613419\",\"GSM3613420\",\"GSM3617822\",\"GSM3319032\",\"GSM3319033\",\n",
    "\"GSM3319034\",\"GSM3319035\",\"GSM3319036\",\"GSM3319037\",\"GSM3319038\",\"GSM3319039\",\"GSM3319040\",\"GSM3319041\",\"GSM3319042\",\"GSM3319043\",\"GSM3319044\",\"GSM3319045\",\"GSM3319046\",\"GSM3319047\",\"GSM3557967\",\"GSM3557969\",\"GSM3557973\",\"GSM3944441\",\"GSM3944442\",\"GSM3944443\",\"GSM3944444\",\"GSM3944445\",\"GSM3944446\",\"GSM3944447\",\"GSM3944448\",\"GSM3944449\",\"GSM3944450\",\"GSM3944451\",\"GSM3944452\",\"GSM3944453\",\n",
    "\"GSM3944454\",\"GSM3944455\",\"GSM3944456\",\"GSM3944457\",\"GSM3944458\",\"GSM3944459\",\"GSM3944460\",\"GSM3944461\",\"GSM3944462\",\"GSM3944463\",\"GSM3944464\",\"GSM3089935\",\"GSM3089936\",\"GSM3089937\",\"GSM3089938\",\"GSM3089946\",\"GSM4073729\",\"GSM4073731\",\"GSM4073733\",\"GSM4073735\",\"GSM4073737\",\"GSM4073739\",\"GSM4073741\",\"GSM4073743\",\"GSM4073745\",\"GSM4073747\",\"GSM4073749\",\"GSM4073752\",\"GSM4073754\",\"GSM4073756\",\n",
    "\"GSM4073758\",\"GSM4073760\",\"GSM4073762\",\"GSM4073764\",\"GSM4073766\",\"GSM4110159\",\"GSM4110160\",\"GSM4110161\"]\n",
    "\n",
    "sample_source = np.repeat(\"ovary\", len(samples_filter_to))\n",
    "\n",
    "sample_labels = np.repeat(\"Ovary\",len(samples_filter_to))\n",
    "\n",
    "genes_filter_to = None\n",
    "\n",
    "\n",
    "#Functional Code\n",
    "\n",
    "#obtain submatrix based on provided filter_to lists\n",
    "with h5py.File(h5_filepath, \"r\") as h5file:\n",
    "    h5_matrix = h5file['data']['expression']\n",
    "    \n",
    "    num_samples = h5_matrix.shape[0]\n",
    "    num_genes = h5_matrix.shape[1]\n",
    "    \n",
    "    all_samples = np.array(h5file[\"meta/Sample_geo_accession\"])\n",
    "    all_genes = np.array(h5file[\"meta/genes\"])\n",
    "\n",
    "    \n",
    "    if samples_filter_to is None:\n",
    "        print(\"No sample filter is specified, do you wish to proceed to cluster on all %d samples?\" % num_samples)\n",
    "\n",
    "        if genes_filter_to is None:\n",
    "            print(\"No gene filter is specified, do you wish to proceed to cluster on all %d genes?\" % num_genes)    \n",
    "            h5_submatrix = h5_matrix\n",
    "        else:\n",
    "            h5_submatrix = h5_matrix[:,np.isin(all_genes,genes_filter_to)]\n",
    "        \n",
    "        \n",
    "        if sample_labels is None:\n",
    "            sample_labels = h5file[\"meta/Sample_source_name_ch1\"]\n",
    "\n",
    "\n",
    "    else:\n",
    "        if genes_filter_to is None:\n",
    "            print(\"No gene filter is specified, do you wish to proceed to cluster on all %d genes?\" % num_genes)    \n",
    "            h5_submatrix = h5_matrix[np.isin(all_samples,samples_filter_to),:]\n",
    "        else:\n",
    "            h5_submatrix = h5_matrix[np.isin(all_samples,samples_filter_to),all_samples,np.isin(all_genes,genes_filter_to)]\n",
    "\n",
    "            \n",
    "        if sample_labels is None:\n",
    "            sample_labels = h5file[\"meta/Sample_source_name_ch1\"][np.isin(all_samples,samples_filter_to)]\n",
    "    \n",
    "    \n",
    "print(h5_submatrix.shape)\n",
    "print(len(sample_labels))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = normalize(h5_submatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gene_expression_cluster_analysis(h5_filepath,\n",
    "                                     samples_filter_to = None,\n",
    "                                     genes_filter_to = None,\n",
    "                                     sample_labels = None,\n",
    "                                     value_transformation = \"raw\",\n",
    "                                     hier_method = \"average\",\n",
    "                                     hier_distance_metric = \"euclidean\",\n",
    "                                     hier_k = 4,\n",
    "                                     hier_fcluster_t = 4):\n",
    "    \n",
    "    \"\"\"\n",
    "Performs gene expression cluster analysis using one or combination of hierarchical, k-means, and SPC.\n",
    "\n",
    "\n",
    "Arguments:\n",
    "\n",
    "    h5_filepath (str): filepath to h5 file of interest (human, mouse)\n",
    "    \n",
    "    samples_filter_to (list [str]): list of samples to filter to in matrix. \n",
    "                       If None, then all samples will be analyzed\n",
    "                       \n",
    "    genes_filter_to (list [str]): list of genes to filter to in matrix.\n",
    "                       If None, then all genes will be analyzed\n",
    "    \n",
    "    sample_labels (list [str]): list of same length as samples_filter_to that \n",
    "                   labels the source tissue/cell line from which\n",
    "                   the sample was obtained from. If None, then\n",
    "                   Sample_source_name_ch1 from h5 metadata will\n",
    "                   be used\n",
    "                   \n",
    "    value_transformation (str): how to transform the values in the h5 matrix\n",
    "                          can be one of [\"raw\",\"normalize\",\"binary\"]\n",
    "                          \"raw\" by default\n",
    "                          TODO: implement library size,\n",
    "                                          DESeq, \n",
    "                                          Relative Log Expression (RLE), \n",
    "                                          upper quartile (UQ), \n",
    "                                          Trimmed Mean of M values (TMM),\n",
    "                                          Total Ubiquitous (TU), \n",
    "                                          Network Centrality Scaling (NCS), \n",
    "                                          Evolution Strategy (ES),\n",
    "                                          pooled size factors (Pooled) (Lun et. al),\n",
    "                                          SCnorm\n",
    "    hier_method (str): specify the method of hierarhcical linkage to be one of \n",
    "                 ('average', 'complete', 'single', 'weighted', 'centroid', 'median' , 'ward')\n",
    "    \n",
    "    hier_distance_metric (str): specify the distance metric used in hierarchical clustering to be one of:\n",
    "                                (‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’, ‘correlation’, ‘cosine’, \n",
    "                                ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘jensenshannon’, ‘kulsinski’, ‘mahalanobis’, \n",
    "                                ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’, \n",
    "                                ‘sokalsneath’, ‘sqeuclidean’, ‘yule’)\n",
    "                 \n",
    "    \n",
    "    hier_k (int): Number of clusters to output from hierarchical clustering. Default to 4\n",
    "    \n",
    "    hier_fcluster_metric (str): one of ('inconsistent','distance','maxclust','monocrit','maxclust_monocrit')\n",
    "    \n",
    "    hier_fcluster_t (float): https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.fcluster.html\n",
    "                                    \n",
    "    Returns:\n",
    "\n",
    "    hier_cluster_dendrogram (matplotlib.pyplot): dendrogram of chosen hierarchical clustering procedure\n",
    "    \"\"\"\n",
    "    \n",
    "    #get submatrix based on filter_to arguments\n",
    "    h5_submatrix, sample_labels = filter_matrix(h5_filepath,samples_filter_to,genes_filter_to)\n",
    "    #make sure sample labels is same length as number of samples in submatrix\n",
    "    #otherwise a data entry error occurred and we need to terminate\n",
    "    if h5_submatrix.shape[0] != len(sample_labels):\n",
    "        print(\"Error: provided sample_labels not the correct length. Terminating program\")\n",
    "        return\n",
    "    \n",
    "    #Go through possible value normalizing transformations\n",
    "    \n",
    "    if value_transformation == \"normalize\":\n",
    "        transformed_submatrix = normalize(h5_submatrix)\n",
    "    #other normalizations to implement\n",
    "    #elif value_transformation == \"\":\n",
    "    else:\n",
    "        transformed_submatrix = h5_submatrix\n",
    "        \n",
    "        \n",
    "    hier_title=hier_method+\" Link Hierarchical Dendrogram, \"+hier_distance_metric+\", \"+value_transformation    \n",
    "    hier_clustering = hierarchical_clustering(transformed_submatrix, \n",
    "                                              method=hier_method, \n",
    "                                              metric=hier_metric, \n",
    "                                              title=hier_title)\n",
    "        \n",
    "    hier_cluster_assignments = fcluster(clustering, hier_k, criterion='maxclust')\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Performs Hierarchical Clustering and returns\n",
    "\n",
    "\"\"\"\n",
    "def hierarchical_clustering(df,title,method=\"average\",metric=\"euclidean\"):\n",
    "    clustering = shc.linkage(df, method=method, metric=metric)\n",
    "    #plt.figure(figsize=(25, 20))  \n",
    "    #plt.title(title)  \n",
    "\n",
    "    #dend = shc.dendrogram(clustering) \n",
    "    print(\"Cophenet = \" + str(cophenet(clustering, pdist(df))[0]))\n",
    "    return(clustering)\n",
    "\n",
    "\"\"\"\n",
    "normalizes (L2) a gene expression matrix such that sum of values for each sample equals 0\n",
    "and each row (sample) has same standard deviation\n",
    "\"\"\"\n",
    "def normalize(X):\n",
    "    return (X - np.mean(X,axis=1).reshape(X.shape[0],1))/np.linalg.norm((X - np.mean(X,axis=1).reshape(X.shape[0],1)),ord=2,axis=1).reshape(X.shape[0],1)\n",
    "\n",
    "#converts to df to binary dataframe, 0 representing that the previous value was 0, and 1 indicating a nonzero value\n",
    "def df_to_binary(df_expression):    \n",
    "    temp = df_expression.copy()\n",
    "    num_rows = len(temp)\n",
    "    for c in range(len(df_expression.columns)):\n",
    "        nonzero_inds = df_expression.iloc[:,c].to_numpy().nonzero()[0]\n",
    "        temp_col = np.zeros(num_rows)\n",
    "        temp_col[nonzero_inds] = 1\n",
    "        temp.iloc[:,c] = temp_col\n",
    "    return(temp)\n",
    "\n",
    "\n",
    "def filter_matrix(h5_filepath,\n",
    "                  samples_filter_to, \n",
    "                  genes_filter_to, \n",
    "                  sample_labels):\n",
    "    \n",
    "    #obtain submatrix based on provided filter_to lists\n",
    "    with h5py.File(h5_filepath, \"r\") as h5file:\n",
    "        h5_matrix = h5file['data']['expression']\n",
    "\n",
    "        num_samples = h5_matrix.shape[0]\n",
    "        num_genes = h5_matrix.shape[1]\n",
    "\n",
    "        all_samples = np.array(h5file[\"meta/Sample_geo_accession\"])\n",
    "        all_genes = np.array(h5file[\"meta/genes\"])\n",
    "\n",
    "\n",
    "        if samples_filter_to is None:\n",
    "            print(\"No sample filter is specified, do you wish to proceed to cluster on all %d samples?\" % num_samples)\n",
    "\n",
    "            if genes_filter_to is None:\n",
    "                print(\"No gene filter is specified, do you wish to proceed to cluster on all %d genes?\" % num_genes)    \n",
    "                h5_submatrix = h5_matrix\n",
    "            else:\n",
    "                h5_submatrix = h5_matrix[:,np.isin(all_genes,genes_filter_to)]\n",
    "\n",
    "\n",
    "            if sample_labels is None:\n",
    "                sample_labels = h5file[\"meta/Sample_source_name_ch1\"]\n",
    "\n",
    "\n",
    "        else:\n",
    "            if genes_filter_to is None:\n",
    "                print(\"No gene filter is specified, do you wish to proceed to cluster on all %d genes?\" % num_genes)    \n",
    "                h5_submatrix = h5_matrix[np.isin(all_samples,samples_filter_to),:]\n",
    "            else:\n",
    "                h5_submatrix = h5_matrix[np.isin(all_samples,samples_filter_to),all_samples,np.isin(all_genes,genes_filter_to)]\n",
    "\n",
    "\n",
    "            if sample_labels is None:\n",
    "                sample_labels = h5file[\"meta/Sample_source_name_ch1\"][np.isin(all_samples,samples_filter_to)]\n",
    "\n",
    "    return(h5_submatrix,sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19044021"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Shaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"ALPHA_expression.csv\",\"beta_expression.csv\",\"PANC1_expression.csv\"]\n",
    "df,sample_source = preprocess_samples(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let X be N (genes) x P (samples) expression matrix (pandas dataframe)\n",
    "def gene_shave(df):\n",
    "    #clusters where clusterID (key) also represents the size k, values are a list of inds of genes belonging to cluster\n",
    "    S = {}\n",
    "    xbarSk = {}\n",
    "    #remove rows of all zeros\n",
    "    df_nonzero = df[(df.T != 0).any()]\n",
    "    genes = np.array(df_nonzero.index)\n",
    "    samples = list(df_nonzero.columns)\n",
    "    X = np.array(df_nonzero)\n",
    "    X = (X - np.mean(X,axis=1).reshape(X.shape[0],1))/np.linalg.norm((X - np.mean(X,axis=1).reshape(X.shape[0],1)),ord=2,axis=1).reshape(X.shape[0],1)\n",
    "    X_copy = X.copy()\n",
    "    while(X_copy.shape[0] > 1):\n",
    "        corr = np.corrcoef(np.transpose(X_copy))\n",
    "        w,v = np.linalg.eig(corr)\n",
    "        #leading principal component is vmax\n",
    "        vmax = v[0]\n",
    "        dot_prods = np.dot(X_copy,vmax)\n",
    "        dot_prods_argsort = np.argsort(dot_prods)\n",
    "        #save the inds of top 90% of rows with respect to dot product with vmax\n",
    "        top90perc = np.where(dot_prods_argsort > len(dot_prods_argsort)*0.1)[0]\n",
    "        S[len(top90perc)] = genes[top90perc]\n",
    "        xbarSkhat = np.mean(X_copy[top90perc,:],axis=0)\n",
    "        xbarSk[len(top90perc)] = xbarSkhat\n",
    "        #remove the bottom 10% of X_copy's rows with respect to dot product with vmax\n",
    "        X_copy = X_copy[top90perc,:]\n",
    "        genes = genes[top90perc]\n",
    "    return(S,xbarSk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, xbarSk = gene_shave(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dk(df,k,xbar):\n",
    "    Dks = []\n",
    "    sumVw = 0.0\n",
    "    sumVb = 0.0\n",
    "    #sum over p columns\n",
    "    jcnt = 0\n",
    "       \n",
    "    for j in df.columns: \n",
    "        #sum over each gene in Sk\n",
    "        #print(\"OK\" + str(xbar.shape))\n",
    "        sumVw = np.sum((df.loc[:,j] - xbar[jcnt])**2)\n",
    "        #or i in S[k]:\n",
    "        #    sumVw += (df.loc[i,j] - xbar[jcnt])**2\n",
    "        sumVb = np.sum((xbar[jcnt] - 0)**2)\n",
    "        jcnt += 1\n",
    "    Vw = sumVw/(k*len(df.columns))\n",
    "    Vb = sumVb/len(df.columns)\n",
    "    Vt = Vw+Vb\n",
    "    Dks.append((Vb/Vw)/(1+(Vb/Vw)))\n",
    "    return(Dks[0])\n",
    "\n",
    "def findK(S, xbarSk, df, B=5):\n",
    "    \n",
    "    Gapk = {}\n",
    "    Dks = {}\n",
    "    D_k_b = {}\n",
    "    for k in S:\n",
    "        print(k)\n",
    "        D_k_b[k] = []\n",
    "        D_k = Dk(df.loc[S[k],:],k,xbarSk[k])\n",
    "        for i in range(B):\n",
    "            df_copy = df.sample(k,replace=False)\n",
    "            xbar = np.mean(np.array(df_copy),axis=0)\n",
    "            D_k_b[k].append(Dk(df,k,xbar))\n",
    "        Dks[k] = (D_k)\n",
    "    return(Dks,D_k_b)\n",
    "        \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the optimum value of k based on R^2 values. Choose the value of k with the highest value\n",
    "df_nonzero = df[(df.T != 0).any()]\n",
    "genes = np.array(df_nonzero.index)\n",
    "X = np.array(df_nonzero)\n",
    "X = (X - np.mean(X,axis=1).reshape(X.shape[0],1))/np.linalg.norm((X - np.mean(X,axis=1).reshape(X.shape[0],1)),ord=2,axis=1).reshape(X.shape[0],1)\n",
    "df_norm = pd.DataFrame(X,index=df_nonzero.index,columns=df_nonzero.columns)\n",
    "Dks,Dkbs = findK(S, xbarSk , df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select genes for visualization purposes (k=6 seems to be the winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapK = {}\n",
    "for i in Dks:\n",
    "    gapK[i] = Dks[i] - np.mean(Dkbs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_nonzero.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer fcluster output to csv for R heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDF(df, cluster_assignments, outfile):\n",
    "    sample_list_sorted = []\n",
    "    for i in np.unique(cluster_assignments):\n",
    "        for j in list(df.index[cluster_assignments == i]):\n",
    "            sample_list_sorted.append(j)\n",
    "    df.loc[sample_list_sorted,:].to_csv(outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortDF(np.transpose(df_norm),fcluster(clustering, len(sample_list), criterion='maxclust'),\"haha.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcluster(clustering, len(df_expression_trans), criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expression_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_sorted = []\n",
    "for i in np.unique(test_ass):\n",
    "    for j in test_ass[test_ass == i]:\n",
    "        sample_list_sorted.append(sample_list[i])\n",
    "df_expression_trans.loc[sample_list_sorted,:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import sqlite3 #sqlite will suffice due to small magnitude of projected data\n",
    "from sqlite3 import Error\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"PANC1_expression.csv\",\"ALPHA_expression.csv\",\"beta_expression.csv\"]\n",
    "df,sample_source = preprocess_samples(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelist = ['AC114755.7', 'APBA1', 'ARNTL', 'C11ORF98', 'C20ORF85', 'C21ORF62',\n",
    "       'C2ORF54', 'CCDC166', 'CDK3', 'CERS5', 'CTC-459F4.7', 'DDR1',\n",
    "       'DGKK', 'ELF2', 'FAM206BP', 'FAM90A13P', 'FDCSP', 'FGF7P1',\n",
    "       'FLYWCH2', 'FOXK2', 'GABBR2', 'GADD45B', 'GIGYF1', 'GIMAP3P',\n",
    "       'GJA4', 'GKAP1', 'GOLGA8J', 'GRM2', 'GSTA7P', 'GUSBP6', 'HMG20B',\n",
    "       'HMGA1P2', 'HNRNPA3P15', 'HNRNPH1P2', 'HSFY4P', 'IGHV3-13',\n",
    "       'IGKV2D-14', 'IGKV3-31', 'KCNA6', 'LCE2B', 'LPXN', 'MCM2', 'MED27',\n",
    "       'MICU2', 'MTCO3P35', 'NECAP1', 'NPY', 'NTM', 'PCDHGA1', 'PHLDB3',\n",
    "       'PHLPP2', 'PIWIL3', 'PPIL1', 'PRODH', 'RERGL', 'RIMBP3B', 'RNF20',\n",
    "       'RP11-102M11.1', 'RP11-117N2.2', 'RP11-163O19.8', 'RP11-170N16.2',\n",
    "       'RP11-252A24.2', 'RP11-345J4.5', 'RP11-463J7.3', 'RP11-56P9.8',\n",
    "       'RP11-69M1.3', 'RP11-72M10.8', 'RP11-790I12.3', 'RP11-848P1.9',\n",
    "       'RP6-149D17.1', 'RPL12P39', 'RPL17-C18ORF32', 'RPL22P11',\n",
    "       'RPL31P9', 'SLC27A2', 'SUMO2P7', 'TEX37', 'TSPEAR', 'UBL4B',\n",
    "       'ZNF271P']\n",
    "\n",
    "df = df.loc[genelist,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_cv(model_dict, X_dict, y, cv = 4, scoring = [\"accuracy\", \"f1_micro\", \"f1_macro\"]):\n",
    "    output_dict = {}\n",
    "    for model_name in list(model_dict.keys()):\n",
    "        for X_name in list(X_dict.keys()):\n",
    "            model = model_dict[model_name]\n",
    "            print(model)\n",
    "            X = X_dict[X_name]\n",
    "            #print(X)\n",
    "            output_dict[model_name + \" + \" + X_name] = {\"accuracy\":None, \"f1_micro\":None, \"f1_macro\":None}\n",
    "            for score in scoring:\n",
    "                scores = cross_val_score(model, X, y, cv=6, scoring = score)\n",
    "                output_dict[model_name + \" + \" + X_name][score] = scores.mean()\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"XGBoost eta0.1\":XGBClassifier(eta = 0.1),\n",
    "        \"XGBoost eta0.2\":XGBClassifier(eta = 0.2),\n",
    "        \"XGBoost eta0.3\":XGBClassifier(eta = 0.3),\n",
    "        \"XGBoost md3\":XGBClassifier(max_depth = 3),\n",
    "        \"XGBoost md4\":XGBClassifier(max_depth = 4),\n",
    "        \"XGBoost md5\":XGBClassifier(max_depth = 5),\n",
    "        \"XGBoost md6\":XGBClassifier(max_depth = 6),\n",
    "        \"XGBoost md7\":XGBClassifier(max_depth = 7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inds = np.array(range(len(sample_source)))\n",
    "\n",
    "inds = np.random.choice(inds,len(inds))\n",
    "\n",
    "train_X = np.transpose(np.array(df.iloc[:,inds]))\n",
    "train_y = np.array(pd.get_dummies(pd.Series(sample_source)).iloc[inds,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "\n",
    "y = np.array(pd.get_dummies(pd.Series(sample_source)))\n",
    "\n",
    "for i in y:\n",
    "    for k in range(3):\n",
    "        if i[k]==1:\n",
    "            train_y.append(k)\n",
    "\n",
    "train_y = np.array(train_y)[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = (train_X - np.mean(train_X,axis=0))/(np.max(train_X,axis=0) - np.min(train_X,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_cv(models,{\"norm\":train_X},train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(sample_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[615,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_source[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
