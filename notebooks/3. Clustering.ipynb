{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import h5py\n",
    "from io import StringIO\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "import itertools\n",
    "import xlsxwriter as Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gene_expression_cluster_analysis(h5_filepath,\n",
    "                                     samples_filter_to = None,\n",
    "                                     genes_filter_to = None,\n",
    "                                     sample_labels = None,\n",
    "                                     value_transformation = \"raw\",\n",
    "                                     hier_method = \"average\",\n",
    "                                     hier_distance_metric = \"euclidean\",\n",
    "                                     hier_k = 4,\n",
    "                                     hier_fcluster_t = 4,\n",
    "                                     output_xlsx_folder = \".\",\n",
    "                                     output_dendro_folder=\".\"):\n",
    "    \n",
    "    \"\"\"\n",
    "Performs gene expression cluster analysis using one or combination of hierarchical, k-means, and SPC.\n",
    "\n",
    "\n",
    "Arguments:\n",
    "\n",
    "    h5_filepath (str): filepath to h5 file of interest (human, mouse)\n",
    "    \n",
    "    samples_filter_to (list [str]): list of samples to filter to in matrix. \n",
    "                       If None, then all samples will be analyzed\n",
    "                       \n",
    "    genes_filter_to (list [str]): list of genes to filter to in matrix.\n",
    "                       If None, then all genes will be analyzed\n",
    "    \n",
    "    sample_labels (list [str]): list of same length as samples_filter_to that \n",
    "                   labels the source tissue/cell line from which\n",
    "                   the sample was obtained from. If None, then\n",
    "                   Sample_source_name_ch1 from h5 metadata will\n",
    "                   be used\n",
    "                   \n",
    "    value_transformation (str): how to transform the values in the h5 matrix\n",
    "                          can be one of [\"raw\",\"normalize\",\"binary\"]\n",
    "                          \"raw\" by default\n",
    "                          TODO: implement library size,\n",
    "                                          DESeq, \n",
    "                                          Relative Log Expression (RLE), \n",
    "                                          upper quartile (UQ), \n",
    "                                          Trimmed Mean of M values (TMM),\n",
    "                                          Total Ubiquitous (TU), \n",
    "                                          Network Centrality Scaling (NCS), \n",
    "                                          Evolution Strategy (ES),\n",
    "                                          pooled size factors (Pooled) (Lun et. al),\n",
    "                                          SCnorm\n",
    "    hier_method (str): specify the method of hierarhcical linkage to be one of \n",
    "                 ('average', 'complete', 'single', 'weighted', 'centroid', 'median' , 'ward')\n",
    "    \n",
    "    hier_distance_metric (str): specify the distance metric used in hierarchical clustering to be one of:\n",
    "                                (‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’, ‘correlation’, ‘cosine’, \n",
    "                                ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘jensenshannon’, ‘kulsinski’, ‘mahalanobis’, \n",
    "                                ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’, \n",
    "                                ‘sokalsneath’, ‘sqeuclidean’, ‘yule’)\n",
    "                 \n",
    "    \n",
    "    hier_k (int): Number of clusters to output from hierarchical clustering. Default to 4\n",
    "    \n",
    "    hier_fcluster_metric (str): one of ('inconsistent','distance','maxclust','monocrit','maxclust_monocrit')\n",
    "    \n",
    "    hier_fcluster_t (float): https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.fcluster.html\n",
    "                                    \n",
    "    output_xlsx_folder: where to save the generated purity tables for each cluster_method+cluster\n",
    "    \n",
    "    output_dendro_folder: where to save generated dendrograms from hierarchical clustering\n",
    "    \n",
    "    Returns:\n",
    "\n",
    "    hier_cluster_dendrogram (matplotlib.pyplot): dendrogram of chosen hierarchical clustering procedure\n",
    "    \"\"\"\n",
    "    \n",
    "    #get submatrix based on filter_to arguments\n",
    "    h5_submatrix, sample_labels = filter_matrix(h5_filepath,samples_filter_to,genes_filter_to,sample_labels)\n",
    "    #make sure sample labels is same length as number of samples in submatrix\n",
    "    #otherwise a data entry error occurred and we need to terminate\n",
    "    if h5_submatrix.shape[0] != len(sample_labels):\n",
    "        print(\"Error: provided sample_labels not the correct length. Terminating program\")\n",
    "        return\n",
    "    \n",
    "    #Go through possible value normalizing transformations\n",
    "    \n",
    "    if value_transformation == \"normalize\":\n",
    "        transformed_submatrix = pd.DataFrame(normalize(np.array(h5_submatrix)),index=h5_submatrix.index,columns=h5_submatrix.columns)\n",
    "    #other normalizations to implement\n",
    "    #elif value_transformation == \"\":\n",
    "    else:\n",
    "        transformed_submatrix = h5_submatrix\n",
    "            \n",
    "    hier_title=hier_method+\" Link Hierarchical Dendrogram, \"+hier_distance_metric+\", \"+value_transformation    \n",
    "    hier_clustering = hierarchical_clustering(transformed_submatrix, \n",
    "                                              method=hier_method, \n",
    "                                              metric=hier_distance_metric, \n",
    "                                              title=hier_title)\n",
    "        \n",
    "    hier_cluster_assignments = fcluster(hier_clustering, hier_fcluster_t, criterion='maxclust')\n",
    "    \n",
    "    get_purity(h5_filepath, hier_cluster_assignments, hier_k, transformed_submatrix, sample_labels, hier_title, output_xlsx_folder)\n",
    "      \n",
    "        \n",
    "    plt.figure(figsize=(25, 20))  \n",
    "    plt.title(hier_title)  \n",
    "    dend = shc.dendrogram(hier_clustering)\n",
    "    plt.savefig('foo.png')\n",
    "        \n",
    "    return(hier_clustering, hier_cluster_assignments)\n",
    "    \n",
    "\n",
    "#INPUTS: \n",
    "#  h5filepath: path where the full matrix is stored with meta and expression data\n",
    "#  subsamples: a pandas DataFrame that must contain a column (foreign key) called SampleGeoAccession\n",
    "#OUTPUT\n",
    "#  merged dataframe of length(subsamples) merged with relevant meta/Sample values for cluster analysis\n",
    "def h5_sample_meta_lookup(h5filepath,subsamples,sample_labels):\n",
    "    f = h5py.File(h5filepath, 'r')\n",
    "    full_data = pd.DataFrame({\"Description\":f[(\"meta/Sample_description\")], \n",
    "                          \"Characteristics\":f[(\"meta/Sample_characteristics_ch1\")],\n",
    "                          \"SampleGeoAccession\":f[(\"meta/Sample_geo_accession\")],\n",
    "                          \"Series ID\":f[(\"meta/Sample_series_id\")],\n",
    "                          \"Molecule\":f[\"meta/Sample_molecule_ch1\"],\n",
    "                          \"Source Name\":f[\"meta/Sample_title\"]})\n",
    "    f.close()\n",
    "    full_data[\"SampleGeoAccession\"] = full_data[\"SampleGeoAccession\"].apply(lambda x : x.decode(\"utf-8\"))\n",
    "    cluster_meta = subsamples.merge(full_data,on=\"SampleGeoAccession\",how=\"left\")\n",
    "    cluster_meta[\"Sample_Label\"] = pd.Series(sample_labels).str.replace(\".csv\",\"\").str.replace(\"_expression\",\" \")\n",
    "    cluster_meta[\"Series ID\"] = cluster_meta[\"Series ID\"].str.decode(\"utf-8\").str.replace(\"Xx\",\"\").str.replace(\"xX\",\"\")\n",
    "    cluster_meta[\"Molecule\"] = cluster_meta[\"Molecule\"].str.decode(\"utf-8\")\n",
    "    cluster_meta[\"Source Name\"] = cluster_meta[\"Source Name\"].str.decode(\"utf-8\")\n",
    "    cluster_meta[\"Description\"] = cluster_meta[\"Description\"].str.decode(\"utf-8\").str.replace(\"Xx\",\"\").str.replace(\"xX\",\"\")\n",
    "    cluster_meta[\"Characteristics\"] = cluster_meta[\"Characteristics\"].str.decode(\"utf-8\").str.replace(\"Xx\",\"\").str.replace(\"xX\",\"\")\n",
    "    return(cluster_meta)\n",
    "\n",
    "def purity_to_excel(cluster_metadata_metrics, H0, out_filepath):\n",
    "    workbook = Excel.Workbook(out_filepath)\n",
    "    worksheet = workbook.add_worksheet()\n",
    "    cluster_format = workbook.add_format({'bold': True, 'align':'center'})\n",
    "    center = workbook.add_format({'align': 'center'})\n",
    "\n",
    "    # Add a format. Light red fill with dark red text.\n",
    "    format1 = workbook.add_format({'bg_color': '#FFC7CE',\n",
    "                                   'font_color': '#9C0006'})\n",
    "\n",
    "    # Add a format. Green fill with dark green text.\n",
    "    format2 = workbook.add_format({'bg_color': '#C6EFCE',\n",
    "                                   'font_color': '#006100'})\n",
    "\n",
    "    worksheet.write('A1', \"Cluster ID\",cluster_format)\n",
    "    worksheet.write('B1', \"Cluster Size\",center)\n",
    "    worksheet.write('C1', \"Dominant Molecule\",center)\n",
    "    worksheet.write('D1', \"Molecule Purity\",center)\n",
    "    worksheet.write('E1', \"Dominant Series\",center)\n",
    "    worksheet.write('F1', \"Series Purity\",center)\n",
    "    worksheet.write('G1', \"Dominant Label\",center)\n",
    "    worksheet.write('H1', \"Label Purity\",center)\n",
    "    worksheet.write('I1', \"Null Hypothesis Value\",center)\n",
    "\n",
    "    worksheet.set_column(1, 7, 15)\n",
    "\n",
    "    num_keys = len(list(cluster_metadata_metrics.keys()))\n",
    "\n",
    "    j = 1\n",
    "    for i in np.sort(list(cluster_metadata_metrics.keys())):\n",
    "        worksheet.write(j,0,i,center)\n",
    "        worksheet.write(j,1,cluster_metadata_metrics[i][\"Size\"],center)\n",
    "        worksheet.write(j,2,list(cluster_metadata_metrics[i][\"Molecule Purity\"].keys())[0],center)\n",
    "        worksheet.write(j,3,list(cluster_metadata_metrics[i][\"Molecule Purity\"].values())[0],center)\n",
    "        worksheet.write(j,4,list(cluster_metadata_metrics[i][\"Series Purity\"].keys())[0],center)\n",
    "        worksheet.write(j,5,list(cluster_metadata_metrics[i][\"Series Purity\"].values())[0],center)\n",
    "        worksheet.write(j,6,list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0],center)\n",
    "        worksheet.write(j,7,list(cluster_metadata_metrics[i][\"Label Purity\"].values())[0],center)\n",
    "        worksheet.write(j,8,H0[list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0]],center)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Write a conditional format over a range.\n",
    "        worksheet.conditional_format('H'+str(j+1), {'type': 'cell',\n",
    "                                             'criteria': '>=',\n",
    "                                             'value': H0[list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0]],\n",
    "                                             'format': format2})\n",
    "\n",
    "        # Write another conditional format over the same range.\n",
    "        worksheet.conditional_format('H'+str(j+1), {'type': 'cell',\n",
    "                                             'criteria': '<',\n",
    "                                             'value': H0[list(cluster_metadata_metrics[i][\"Label Purity\"].keys())[0]],\n",
    "                                             'format': format1})\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    workbook.close()\n",
    "\n",
    "\n",
    "def get_purity(h5_filepath, cluster_assignments, k, df_expression_trans,sample_labels,cluster_title,output_xlsx_folder):\n",
    "    cluster_dict = {\"SampleGeoAccession\":[],\"ClusterAssignment\":[]}\n",
    "    cluster_dict[\"SampleGeoAccession\"] = df_expression_trans.index\n",
    "    cluster_dict[\"ClusterAssignment\"] = cluster_assignments\n",
    "    cluster_info = pd.DataFrame(cluster_dict)\n",
    "    cluster_metadata = h5_sample_meta_lookup(h5_filepath,cluster_info,sample_labels).sort_values(\"ClusterAssignment\")\n",
    "    \n",
    "    #hypothesized values of expected sample frequencies assuminfg no separation (based on observed proportion of sample labels)\n",
    "    H0 = {}\n",
    "    for samp in cluster_metadata.Sample_Label:\n",
    "        H0[samp] = len(cluster_metadata[cluster_metadata.Sample_Label == samp])/len(cluster_metadata)\n",
    "    \n",
    "    cluster_metadata_metrics = {}\n",
    "    for c in range(1,k+1):\n",
    "        cluster_metadata_metrics[c] = {\"Size\":len(cluster_metadata.loc[cluster_metadata.ClusterAssignment == c]), \n",
    "                                       \"Molecule Purity\":{},\"Series Purity\":{},\"Label Purity\":{}}\n",
    "        series_counts = cluster_metadata.groupby('ClusterAssignment')[\"Series ID\"].value_counts()\n",
    "        molecule_counts = cluster_metadata.groupby('ClusterAssignment')[\"Molecule\"].value_counts()\n",
    "        label_counts = cluster_metadata.groupby('ClusterAssignment')[\"Sample_Label\"].value_counts()\n",
    "\n",
    "        series_purity_key = pd.Series(series_counts[c][series_counts[c] == series_counts[c].max()]).index[0]\n",
    "        series_purity_val = series_counts[c].max()/float(series_counts[c].sum())\n",
    "        cluster_metadata_metrics[c][\"Series Purity\"][series_purity_key] = round(series_purity_val,3)\n",
    "\n",
    "        molecule_purity_key = molecule_counts[c][molecule_counts[c] == molecule_counts[c].max()].index[0]\n",
    "        molecule_purity_val = molecule_counts[c].max()/float(molecule_counts[c].sum())\n",
    "        cluster_metadata_metrics[c][\"Molecule Purity\"][molecule_purity_key] = round(molecule_purity_val,3)\n",
    "\n",
    "        label_purity_key = label_counts[c][label_counts[c] == label_counts[c].max()].index[0]\n",
    "        label_purity_val = label_counts[c].max()/float(label_counts[c].sum())\n",
    "        cluster_metadata_metrics[c][\"Label Purity\"][label_purity_key] = round(label_purity_val,3)\n",
    "    purity_to_excel(cluster_metadata_metrics,H0,os.path.join(output_xlsx_folder,cluster_title+\" purity\" + \".xlsx\") )\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Performs Hierarchical Clustering and returns\n",
    "\n",
    "\"\"\"\n",
    "def hierarchical_clustering(df,title,method=\"average\",metric=\"euclidean\"):\n",
    "    clustering = shc.linkage(df, method=method, metric=metric)\n",
    "    #plt.figure(figsize=(25, 20))  \n",
    "    #plt.title(title)  \n",
    "\n",
    "    #dend = shc.dendrogram(clustering) \n",
    "    print(\"Cophenet = \" + str(cophenet(clustering, pdist(df))[0]))\n",
    "    return(clustering)\n",
    "\n",
    "\"\"\"\n",
    "normalizes (L2) a gene expression matrix such that sum of values for each sample equals 0\n",
    "and each row (sample) has same standard deviation\n",
    "\"\"\"\n",
    "def normalize(X):\n",
    "    return (X - np.mean(X,axis=1).reshape(X.shape[0],1))/np.linalg.norm((X - np.mean(X,axis=1).reshape(X.shape[0],1)),ord=2,axis=1).reshape(X.shape[0],1)\n",
    "\n",
    "#converts to df to binary dataframe, 0 representing that the previous value was 0, and 1 indicating a nonzero value\n",
    "def df_to_binary(df_expression):    \n",
    "    temp = df_expression.copy()\n",
    "    num_rows = len(temp)\n",
    "    for c in range(len(df_expression.columns)):\n",
    "        nonzero_inds = df_expression.iloc[:,c].to_numpy().nonzero()[0]\n",
    "        temp_col = np.zeros(num_rows)\n",
    "        temp_col[nonzero_inds] = 1\n",
    "        temp.iloc[:,c] = temp_col\n",
    "    return(temp)\n",
    "\n",
    "\n",
    "def filter_matrix(h5_filepath,\n",
    "                  samples_filter_to, \n",
    "                  genes_filter_to,\n",
    "                 sample_labels):\n",
    "    \n",
    "    samples_filter_to = list(map(lambda x : bytes(x,encoding=\"utf-8\"),samples_filter_to))\n",
    "    \n",
    "    #obtain submatrix based on provided filter_to lists\n",
    "    with h5py.File(h5_filepath, \"r\") as h5file:\n",
    "        h5_matrix = h5file['data']['expression']\n",
    "\n",
    "        num_samples = h5_matrix.shape[0]\n",
    "        num_genes = h5_matrix.shape[1]\n",
    "\n",
    "        all_samples = map(lambda x : str(x,encoding=\"utf-8\"),np.array(h5file[\"meta/Sample_geo_accession\"]))\n",
    "        all_genes = map(lambda x : str(x,encoding=\"utf-8\"),np.array(h5file[\"meta/genes\"]))\n",
    "\n",
    "        if samples_filter_to is None:\n",
    "            print(\"No sample filter is specified, do you wish to proceed to cluster on all %d samples?\" % num_samples)\n",
    "\n",
    "            if genes_filter_to is None:\n",
    "                print(\"No gene filter is specified, do you wish to proceed to cluster on all %d genes?\" % num_genes)    \n",
    "                h5_submatrix = h5_matrix\n",
    "                inds = all_samples\n",
    "                cols = all_genes\n",
    "            else:\n",
    "                h5_submatrix = h5_matrix[:,np.isin(all_genes,genes_filter_to)]\n",
    "                inds = all_samples\n",
    "                cols = genes_filter_to\n",
    "\n",
    "\n",
    "            if sample_labels is None:\n",
    "                sample_labels = h5file[\"meta/Sample_source_name_ch1\"]\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"No gene filter is specified, do you wish to proceed to cluster on all %d genes?\" % num_genes)    \n",
    "            if genes_filter_to is None:\n",
    "                print(\"oy\")\n",
    "                h5_submatrix = h5_matrix[np.isin(all_samples,samples_filter_to),:]\n",
    "                inds = samples_filter_to\n",
    "                cols = all_genes\n",
    "               \n",
    "            else:\n",
    "                h5_submatrix =  np.array(h5_matrix[np.isin(all_samples,samples_filter_to),np.isin(all_genes,genes_filter_to)])\n",
    "                inds = samples_filter_to\n",
    "                cols = genes_filter_to\n",
    "\n",
    "            if sample_labels is None:\n",
    "                sample_labels = h5file[\"meta/Sample_source_name_ch1\"][np.isin(all_samples,samples_filter_to)]\n",
    "\n",
    "    return(pd.DataFrame(h5_submatrix,index=inds,columns=cols),sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filepath = \"../data/raw/human_matrix.h5\"\n",
    "subsample_filepath = \"../data/external/subsample_dict.json\"\n",
    "\n",
    "#extract samples to compare for clustering as in this example using the dictionary json file:\n",
    "with open(subsample_filepath,'r') as f:\n",
    "    subsample_dict = json.loads(f.read())\n",
    "\n",
    "ovary_samples = subsample_dict[\"human\"][\"systems\"][\"urogenital\"][\"Ovary\"]\n",
    "ovary_cell_lines = subsample_dict[\"human\"][\"cell-lines\"][\"ovary\"][\"ES2\"]\n",
    "\n",
    "samples_filter_to = ovary_samples + ovary_cell_lines\n",
    "\n",
    "sample_labels = np.repeat(\"Ovary\",len(samples_filter_to))\n",
    "\n",
    "genes_filter_to = None\n",
    "\n",
    "value_transformation = \"normalize\"\n",
    "\n",
    "hier_method = \"complete\"\n",
    "\n",
    "hier_distance_metric = \"euclidean\"\n",
    "\n",
    "hier_k = 4\n",
    "\n",
    "hier_fcluster_t = 4\n",
    "\n",
    "output_xlsx_folder = \"../data/processed/tables\"\n",
    "\n",
    "output_dendro_folder = \"../data/processed/figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738\n"
     ]
    }
   ],
   "source": [
    "print(len(set(ovary_samples)) +len(set(ovary_cell_lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_filter_to = set(ovary_samples)#+ovary_cell_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x23e02191ef0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(h5_filepath, \"r\") as h5file:\n",
    "    h5_matrix = h5file['data']['expression']\n",
    "    num_samples = h5_matrix.shape[0]\n",
    "    num_genes = h5_matrix.shape[1]\n",
    "    all_samples = np.array(h5file[\"meta/Sample_geo_accession\"])\n",
    "        \n",
    "    sub = h5_matrix[np.isin(all_samples,list(map(lambda x : bytes(x,encoding=\"utf-8\"),samples_filter_to))),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238522"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-62-acdd6cad106a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-62-acdd6cad106a>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    if not bytes(s,encoding=\"|S100\") in all_samples)\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for s in samples_filter_to:\n",
    "    print(repr(s))\n",
    "    if not bytes(s,encoding=\"|S100\") in all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gene filter is specified, do you wish to proceed to cluster on all 35238 genes?\n",
      "oy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (660, 35238), indices imply (738, 35238)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1653\u001b[1;33m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1654\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                 \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 1691\u001b[1;33m         passed, implied))\n\u001b[0m\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (660, 35238), indices imply (738, 35238)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5490cd13bd08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                  \u001b[0mhier_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                  \u001b[0mhier_fcluster_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                  output_xlsx_folder)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-498b10712edc>\u001b[0m in \u001b[0;36mgene_expression_cluster_analysis\u001b[1;34m(h5_filepath, samples_filter_to, genes_filter_to, sample_labels, value_transformation, hier_method, hier_distance_metric, hier_k, hier_fcluster_t, output_xlsx_folder, output_dendro_folder)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m#get submatrix based on filter_to arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mh5_submatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5_filepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_filter_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgenes_filter_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;31m#make sure sample labels is same length as number of samples in submatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m#otherwise a data entry error occurred and we need to terminate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-498b10712edc>\u001b[0m in \u001b[0;36mfilter_matrix\u001b[1;34m(h5_filepath, samples_filter_to, genes_filter_to, sample_labels)\u001b[0m\n\u001b[0;32m    304\u001b[0m                 \u001b[0msample_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta/Sample_source_name_ch1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_filter_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5_submatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 424\u001b[1;33m                                    copy=copy)\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1660\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 1691\u001b[1;33m         passed, implied))\n\u001b[0m\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (660, 35238), indices imply (738, 35238)"
     ]
    }
   ],
   "source": [
    "a = gene_expression_cluster_analysis(h5_filepath,\n",
    "                                 samples_filter_to,\n",
    "                                 genes_filter_to,\n",
    "                                 sample_labels,                                 \n",
    "                                 value_transformation,\n",
    "                                 hier_method,\n",
    "                                 hier_distance_metric,\n",
    "                                 hier_k,\n",
    "                                 hier_fcluster_t,\n",
    "                                 output_xlsx_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Shaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"ALPHA_expression.csv\",\"beta_expression.csv\",\"PANC1_expression.csv\"]\n",
    "df,sample_source = preprocess_samples(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let X be N (genes) x P (samples) expression matrix (pandas dataframe)\n",
    "def gene_shave(df):\n",
    "    #clusters where clusterID (key) also represents the size k, values are a list of inds of genes belonging to cluster\n",
    "    S = {}\n",
    "    xbarSk = {}\n",
    "    #remove rows of all zeros\n",
    "    df_nonzero = df[(df.T != 0).any()]\n",
    "    genes = np.array(df_nonzero.index)\n",
    "    samples = list(df_nonzero.columns)\n",
    "    X = np.array(df_nonzero)\n",
    "    X = (X - np.mean(X,axis=1).reshape(X.shape[0],1))/np.linalg.norm((X - np.mean(X,axis=1).reshape(X.shape[0],1)),ord=2,axis=1).reshape(X.shape[0],1)\n",
    "    X_copy = X.copy()\n",
    "    while(X_copy.shape[0] > 1):\n",
    "        corr = np.corrcoef(np.transpose(X_copy))\n",
    "        w,v = np.linalg.eig(corr)\n",
    "        #leading principal component is vmax\n",
    "        vmax = v[0]\n",
    "        dot_prods = np.dot(X_copy,vmax)\n",
    "        dot_prods_argsort = np.argsort(dot_prods)\n",
    "        #save the inds of top 90% of rows with respect to dot product with vmax\n",
    "        top90perc = np.where(dot_prods_argsort > len(dot_prods_argsort)*0.1)[0]\n",
    "        S[len(top90perc)] = genes[top90perc]\n",
    "        xbarSkhat = np.mean(X_copy[top90perc,:],axis=0)\n",
    "        xbarSk[len(top90perc)] = xbarSkhat\n",
    "        #remove the bottom 10% of X_copy's rows with respect to dot product with vmax\n",
    "        X_copy = X_copy[top90perc,:]\n",
    "        genes = genes[top90perc]\n",
    "    return(S,xbarSk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, xbarSk = gene_shave(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dk(df,k,xbar):\n",
    "    Dks = []\n",
    "    sumVw = 0.0\n",
    "    sumVb = 0.0\n",
    "    #sum over p columns\n",
    "    jcnt = 0\n",
    "       \n",
    "    for j in df.columns: \n",
    "        #sum over each gene in Sk\n",
    "        #print(\"OK\" + str(xbar.shape))\n",
    "        sumVw = np.sum((df.loc[:,j] - xbar[jcnt])**2)\n",
    "        #or i in S[k]:\n",
    "        #    sumVw += (df.loc[i,j] - xbar[jcnt])**2\n",
    "        sumVb = np.sum((xbar[jcnt] - 0)**2)\n",
    "        jcnt += 1\n",
    "    Vw = sumVw/(k*len(df.columns))\n",
    "    Vb = sumVb/len(df.columns)\n",
    "    Vt = Vw+Vb\n",
    "    Dks.append((Vb/Vw)/(1+(Vb/Vw)))\n",
    "    return(Dks[0])\n",
    "\n",
    "def findK(S, xbarSk, df, B=5):\n",
    "    \n",
    "    Gapk = {}\n",
    "    Dks = {}\n",
    "    D_k_b = {}\n",
    "    for k in S:\n",
    "        print(k)\n",
    "        D_k_b[k] = []\n",
    "        D_k = Dk(df.loc[S[k],:],k,xbarSk[k])\n",
    "        for i in range(B):\n",
    "            df_copy = df.sample(k,replace=False)\n",
    "            xbar = np.mean(np.array(df_copy),axis=0)\n",
    "            D_k_b[k].append(Dk(df,k,xbar))\n",
    "        Dks[k] = (D_k)\n",
    "    return(Dks,D_k_b)\n",
    "        \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the optimum value of k based on R^2 values. Choose the value of k with the highest value\n",
    "df_nonzero = df[(df.T != 0).any()]\n",
    "genes = np.array(df_nonzero.index)\n",
    "X = np.array(df_nonzero)\n",
    "X = (X - np.mean(X,axis=1).reshape(X.shape[0],1))/np.linalg.norm((X - np.mean(X,axis=1).reshape(X.shape[0],1)),ord=2,axis=1).reshape(X.shape[0],1)\n",
    "df_norm = pd.DataFrame(X,index=df_nonzero.index,columns=df_nonzero.columns)\n",
    "Dks,Dkbs = findK(S, xbarSk , df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select genes for visualization purposes (k=6 seems to be the winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapK = {}\n",
    "for i in Dks:\n",
    "    gapK[i] = Dks[i] - np.mean(Dkbs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_nonzero.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer fcluster output to csv for R heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDF(df, cluster_assignments, outfile):\n",
    "    sample_list_sorted = []\n",
    "    for i in np.unique(cluster_assignments):\n",
    "        for j in list(df.index[cluster_assignments == i]):\n",
    "            sample_list_sorted.append(j)\n",
    "    df.loc[sample_list_sorted,:].to_csv(outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortDF(np.transpose(df_norm),fcluster(clustering, len(sample_list), criterion='maxclust'),\"haha.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcluster(clustering, len(df_expression_trans), criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expression_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_sorted = []\n",
    "for i in np.unique(test_ass):\n",
    "    for j in test_ass[test_ass == i]:\n",
    "        sample_list_sorted.append(sample_list[i])\n",
    "df_expression_trans.loc[sample_list_sorted,:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import sqlite3 #sqlite will suffice due to small magnitude of projected data\n",
    "from sqlite3 import Error\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"PANC1_expression.csv\",\"ALPHA_expression.csv\",\"beta_expression.csv\"]\n",
    "df,sample_source = preprocess_samples(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelist = ['AC114755.7', 'APBA1', 'ARNTL', 'C11ORF98', 'C20ORF85', 'C21ORF62',\n",
    "       'C2ORF54', 'CCDC166', 'CDK3', 'CERS5', 'CTC-459F4.7', 'DDR1',\n",
    "       'DGKK', 'ELF2', 'FAM206BP', 'FAM90A13P', 'FDCSP', 'FGF7P1',\n",
    "       'FLYWCH2', 'FOXK2', 'GABBR2', 'GADD45B', 'GIGYF1', 'GIMAP3P',\n",
    "       'GJA4', 'GKAP1', 'GOLGA8J', 'GRM2', 'GSTA7P', 'GUSBP6', 'HMG20B',\n",
    "       'HMGA1P2', 'HNRNPA3P15', 'HNRNPH1P2', 'HSFY4P', 'IGHV3-13',\n",
    "       'IGKV2D-14', 'IGKV3-31', 'KCNA6', 'LCE2B', 'LPXN', 'MCM2', 'MED27',\n",
    "       'MICU2', 'MTCO3P35', 'NECAP1', 'NPY', 'NTM', 'PCDHGA1', 'PHLDB3',\n",
    "       'PHLPP2', 'PIWIL3', 'PPIL1', 'PRODH', 'RERGL', 'RIMBP3B', 'RNF20',\n",
    "       'RP11-102M11.1', 'RP11-117N2.2', 'RP11-163O19.8', 'RP11-170N16.2',\n",
    "       'RP11-252A24.2', 'RP11-345J4.5', 'RP11-463J7.3', 'RP11-56P9.8',\n",
    "       'RP11-69M1.3', 'RP11-72M10.8', 'RP11-790I12.3', 'RP11-848P1.9',\n",
    "       'RP6-149D17.1', 'RPL12P39', 'RPL17-C18ORF32', 'RPL22P11',\n",
    "       'RPL31P9', 'SLC27A2', 'SUMO2P7', 'TEX37', 'TSPEAR', 'UBL4B',\n",
    "       'ZNF271P']\n",
    "\n",
    "df = df.loc[genelist,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_cv(model_dict, X_dict, y, cv = 4, scoring = [\"accuracy\", \"f1_micro\", \"f1_macro\"]):\n",
    "    output_dict = {}\n",
    "    for model_name in list(model_dict.keys()):\n",
    "        for X_name in list(X_dict.keys()):\n",
    "            model = model_dict[model_name]\n",
    "            print(model)\n",
    "            X = X_dict[X_name]\n",
    "            #print(X)\n",
    "            output_dict[model_name + \" + \" + X_name] = {\"accuracy\":None, \"f1_micro\":None, \"f1_macro\":None}\n",
    "            for score in scoring:\n",
    "                scores = cross_val_score(model, X, y, cv=6, scoring = score)\n",
    "                output_dict[model_name + \" + \" + X_name][score] = scores.mean()\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"XGBoost eta0.1\":XGBClassifier(eta = 0.1),\n",
    "        \"XGBoost eta0.2\":XGBClassifier(eta = 0.2),\n",
    "        \"XGBoost eta0.3\":XGBClassifier(eta = 0.3),\n",
    "        \"XGBoost md3\":XGBClassifier(max_depth = 3),\n",
    "        \"XGBoost md4\":XGBClassifier(max_depth = 4),\n",
    "        \"XGBoost md5\":XGBClassifier(max_depth = 5),\n",
    "        \"XGBoost md6\":XGBClassifier(max_depth = 6),\n",
    "        \"XGBoost md7\":XGBClassifier(max_depth = 7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inds = np.array(range(len(sample_source)))\n",
    "\n",
    "inds = np.random.choice(inds,len(inds))\n",
    "\n",
    "train_X = np.transpose(np.array(df.iloc[:,inds]))\n",
    "train_y = np.array(pd.get_dummies(pd.Series(sample_source)).iloc[inds,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "\n",
    "y = np.array(pd.get_dummies(pd.Series(sample_source)))\n",
    "\n",
    "for i in y:\n",
    "    for k in range(3):\n",
    "        if i[k]==1:\n",
    "            train_y.append(k)\n",
    "\n",
    "train_y = np.array(train_y)[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = (train_X - np.mean(train_X,axis=0))/(np.max(train_X,axis=0) - np.min(train_X,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_cv(models,{\"norm\":train_X},train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(sample_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[615,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_source[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
